{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0353de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from os import environ\n",
    "# environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "# import tifffile as tiff\n",
    "# import re\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "# from tensorflowkeras.optimizers.schedules import ExponentialDecay\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a55e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input training labels (file and label)\n",
    "train = pd.read_csv('train_labels.csv')\n",
    "#putting labels as string for image generator\n",
    "train['label'] = train['label'].astype(str)\n",
    "#changing labels of files to match filesystem in google colab\n",
    "train['id'] += '.tif'\n",
    "# train['id'] = train['id'].apply(lambda x: 'train/' + x)\n",
    "#creating random state to apply shuffling to data\n",
    "train = shuffle(train, random_state = 42)\n",
    "\n",
    "\n",
    "#split this into training and validation for model\n",
    "train, valid = train_test_split(train, test_size = 0.25)\n",
    "\n",
    "#sample_submission\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "#creating test data frame to import data, creates id col with name of file\n",
    "test = pd.DataFrame({'id':os.listdir('test')})\n",
    "\n",
    "#setting batch size for entire project\n",
    "batch_size = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73eadd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165018 validated image filenames belonging to 2 classes.\n",
      "Found 55007 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#creating method to generate training and validation images\n",
    "#creates validation set of 0.2 size of training data and scales pixels\n",
    "generator_data = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "#getting image generator based upon labels in train df\n",
    "train_generator = generator_data.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory = 'train',\n",
    "    x_col = 'id',\n",
    "    y_col = 'label',\n",
    "    shuffle = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    class_mode = 'binary',\n",
    "    batch_size = batch_size,\n",
    "    random_state = 42,\n",
    "    horizontal_flip = True,\n",
    "    target_size = (96,96)\n",
    ")\n",
    "\n",
    "#getting image generator based upon lables in valid df\n",
    "valid_generator = generator_data.flow_from_dataframe(\n",
    "    dataframe = valid,\n",
    "    directory = 'train',\n",
    "    x_col = 'id',\n",
    "    y_col = 'label', \n",
    "    shuffle = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    class_mode = 'binary',\n",
    "    batch_size = batch_size,\n",
    "    random_state = 42,\n",
    "    horizontal_flip = True,\n",
    "    target_size = (96,96)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca009db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 13:57:03.957646: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-13 13:57:03.957665: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 13:57:04.339657: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-13 13:57:04.578870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.8135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 13:58:00.492976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 74s 224ms/step - loss: 0.4125 - accuracy: 0.8135 - val_loss: 1.0838 - val_accuracy: 0.6094 - lr: 0.0100\n",
      "Epoch 2/10\n",
      "323/323 [==============================] - 72s 223ms/step - loss: 0.3427 - accuracy: 0.8512 - val_loss: 1.1919 - val_accuracy: 0.7189 - lr: 0.0100\n",
      "Epoch 3/10\n",
      "323/323 [==============================] - 72s 223ms/step - loss: 0.3038 - accuracy: 0.8726 - val_loss: 0.3778 - val_accuracy: 0.8334 - lr: 0.0100\n",
      "Epoch 4/10\n",
      "323/323 [==============================] - 69s 215ms/step - loss: 0.2758 - accuracy: 0.8853 - val_loss: 0.8496 - val_accuracy: 0.6859 - lr: 0.0090\n",
      "Epoch 5/10\n",
      "323/323 [==============================] - 72s 222ms/step - loss: 0.2597 - accuracy: 0.8929 - val_loss: 0.5450 - val_accuracy: 0.7795 - lr: 0.0082\n",
      "Epoch 6/10\n",
      "323/323 [==============================] - 71s 219ms/step - loss: 0.2469 - accuracy: 0.8987 - val_loss: 0.3608 - val_accuracy: 0.8481 - lr: 0.0074\n",
      "Epoch 7/10\n",
      "323/323 [==============================] - 71s 219ms/step - loss: 0.2357 - accuracy: 0.9038 - val_loss: 0.5148 - val_accuracy: 0.8186 - lr: 0.0067\n",
      "Epoch 8/10\n",
      "323/323 [==============================] - 70s 218ms/step - loss: 0.2252 - accuracy: 0.9083 - val_loss: 0.3141 - val_accuracy: 0.8727 - lr: 0.0061\n",
      "Epoch 9/10\n",
      "323/323 [==============================] - 71s 220ms/step - loss: 0.2185 - accuracy: 0.9116 - val_loss: 0.5095 - val_accuracy: 0.8200 - lr: 0.0055\n",
      "Epoch 10/10\n",
      "323/323 [==============================] - 70s 217ms/step - loss: 0.2108 - accuracy: 0.9145 - val_loss: 0.4661 - val_accuracy: 0.8290 - lr: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28cfb7190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#beginning model\n",
    "\n",
    "#building model with layers\n",
    "model = Sequential([\n",
    "    Conv2D(16, kernel_size = 3, activation = 'relu', input_shape = (96,96,3), strides = (2,2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(16, kernel_size = 3, activation = 'relu', strides = (2,2)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Conv2D(64, kernel_size = 3, activation = 'relu', strides = (2,2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, kernel_size = 3, activation = 'relu', strides = (2,2)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Flatten(),\n",
    "    Dense(8, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "]);\n",
    "\n",
    "#sgd optimizer\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(learning_rate = 0.01,\n",
    "  nesterov = True,\n",
    "  momentum = 0.99\n",
    ")\n",
    "\n",
    "#learning rate scheduler for improved speed\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "#callback to run learning rate scheduler\n",
    "callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "#model compiler\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#fitting the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 10,\n",
    "    callbacks = [callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f55a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57458 validated image filenames.\n",
      "   54/57458 [..............................] - ETA: 1:49 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:08:58.143171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43093/57458 [=====================>........] - ETA: 27s"
     ]
    }
   ],
   "source": [
    "data_generator_test = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    ")\n",
    "\n",
    "#creating sequence of image generator\n",
    "test_generator = data_generator_test.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory ='test',\n",
    "    x_col = 'id', \n",
    "    y_col = None,\n",
    "    target_size = (96,96),         \n",
    "    batch_size = 1,\n",
    "    shuffle = False,\n",
    "    class_mode = None\n",
    ")\n",
    "\n",
    "\n",
    "#prediction\n",
    "predict = model.predict(\n",
    "    x = test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict)\n",
    "print(sample)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48405d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = np.transpose(predict)[0]\n",
    "submission_df = pd.DataFrame()\n",
    "submission_df['id'] = test['id'].apply(lambda x: x.split('.')[0])\n",
    "submission_df['label'] = list(map(lambda x: 0 if x < 0.5 else 1, predict))\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3c819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
