{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a0353de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from os import environ\n",
    "# environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "# import tifffile as tiff\n",
    "# import re\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "# from tensorflowkeras.optimizers.schedules import ExponentialDecay\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a55e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input training labels (file and label)\n",
    "train = pd.read_csv('train_labels.csv')\n",
    "#putting labels as string for image generator\n",
    "train['label'] = train['label'].astype(str)\n",
    "#changing labels of files to match filesystem in google colab\n",
    "train['id'] += '.tif'\n",
    "# train['id'] = train['id'].apply(lambda x: 'train/' + x)\n",
    "#creating random state to apply shuffling to data\n",
    "train = shuffle(train, random_state = 42)\n",
    "\n",
    "\n",
    "#split this into training and validation for model\n",
    "train, valid = train_test_split(train, test_size = 0.25)\n",
    "\n",
    "#sample_submission\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "#creating test data frame to import data, creates id col with name of file\n",
    "test = pd.DataFrame({'id':os.listdir('test')})\n",
    "\n",
    "#setting batch size for entire project\n",
    "batch_size = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73eadd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165018 validated image filenames belonging to 2 classes.\n",
      "Found 55007 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#creating method to generate training and validation images\n",
    "#creates validation set of 0.2 size of training data and scales pixels\n",
    "generator_data = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "#getting image generator based upon labels in train df\n",
    "train_generator = generator_data.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory = 'train',\n",
    "    x_col = 'id',\n",
    "    y_col = 'label',\n",
    "    shuffle = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    class_mode = 'binary',\n",
    "    batch_size = batch_size,\n",
    "    random_state = 42,\n",
    "    horizontal_flip = True,\n",
    "    target_size = (96,96)\n",
    ")\n",
    "\n",
    "#getting image generator based upon lables in valid df\n",
    "valid_generator = generator_data.flow_from_dataframe(\n",
    "    dataframe = valid,\n",
    "    directory = 'train',\n",
    "    x_col = 'id',\n",
    "    y_col = 'label', \n",
    "    shuffle = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    class_mode = 'binary',\n",
    "    batch_size = batch_size,\n",
    "    random_state = 42,\n",
    "    horizontal_flip = True,\n",
    "    target_size = (96,96)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca009db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 22:33:53.443728: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.8107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 22:34:48.084304: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n",
      "645/645 [==============================] - 73s 113ms/step - loss: 0.4194 - accuracy: 0.8107 - val_loss: 0.3891 - val_accuracy: 0.8284\n",
      "Epoch 2/10\n",
      "645/645 [==============================] - 56s 87ms/step - loss: 0.3477 - accuracy: 0.8479\n",
      "Epoch 3/10\n",
      "645/645 [==============================] - 56s 87ms/step - loss: 0.3224 - accuracy: 0.8614\n",
      "Epoch 4/10\n",
      "645/645 [==============================] - 56s 87ms/step - loss: 0.2996 - accuracy: 0.8743\n",
      "Epoch 5/10\n",
      "645/645 [==============================] - 54s 84ms/step - loss: 0.2809 - accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "645/645 [==============================] - 55s 85ms/step - loss: 0.2671 - accuracy: 0.8891\n",
      "Epoch 7/10\n",
      "645/645 [==============================] - 57s 88ms/step - loss: 0.2540 - accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "645/645 [==============================] - 55s 85ms/step - loss: 0.2423 - accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "645/645 [==============================] - 55s 85ms/step - loss: 0.2398 - accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "645/645 [==============================] - 56s 87ms/step - loss: 0.2243 - accuracy: 0.9088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291878280>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#beginning model\n",
    "\n",
    "#building model with layers\n",
    "model = Sequential([\n",
    "    Conv2D(16, kernel_size = 3, activation = 'relu', input_shape = (96,96,3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(16, kernel_size = 3, activation = 'relu', strides = (2,2)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Conv2D(64, kernel_size = 3, activation = 'relu', strides = (2,2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, kernel_size = 3, activation = 'relu', strides = (2,2)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size = (2,2)),\n",
    "    Flatten(),\n",
    "    Dense(8, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "]);\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(learning_rate = 0.001,\n",
    "  nesterov = True,\n",
    "  momentum = 0.99\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#model compiler\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#fitting the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = 500,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57458 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 22:52:39.406581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57458/57458 [==============================] - 124s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "data_generator_test = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    ")\n",
    "\n",
    "#creating sequence of image generator\n",
    "test_generator = data_generator_test.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory ='test',\n",
    "    x_col = 'id', \n",
    "    y_col = None,\n",
    "    target_size = (96,96),         \n",
    "    batch_size = 1,\n",
    "    shuffle = False,\n",
    "    class_mode = None\n",
    ")\n",
    "\n",
    "\n",
    "#prediction\n",
    "predict = model.predict(\n",
    "    x = test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f0b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
